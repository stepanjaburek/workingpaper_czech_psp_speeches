# -*- coding: utf-8 -*-
"""Plenary-Speech-Translation-EasyNMT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N5Q1eryUD98efyXqH6Q9byaxmjSWUw6Q

#EasyNMT - Example (Opus-MT Model)
This notebook shows the usage of [EasyNMT](https://github.com/UKPLab/EasyNMT) for machine translation.

Here, we use the [Opus-MT model](https://github.com/Helsinki-NLP/Opus-MT). The Helsiniki-NLP group provides 1200+ pre-trained models for various language directions (e.g. en-de, es-fr, ru-fr). Each model has a size of about 300 MB.

We make the usage of the models easy: The suitable model needed for your translation is loaded automatically and kept in memory for future use.
"""

!nvidia-smi

!pip install -U easynmt
!pip install fasttext langid langdetect
!pip install deepmultilingualpunctuation

import pandas as pd
from easynmt import EasyNMT
from tqdm.auto import tqdm
import torch
import os
from deepmultilingualpunctuation import PunctuationModel
from easynmt import EasyNMT
import nltk

"""# Punctuation restoration"""

model = PunctuationModel(model = "kredor/punctuate-all")
text = "moje jméno je Štěpán a bydlím v Praze jak se máš"
result = model.restore_punctuation(text)
print(result)

#df = pd.read_csv('/content/wto_kwic.csv')
#df['context_full_punctuation'] = df['context_full'].apply(model.restore_punctuation)
#df.to_csv('/content/wto_kwic.csv', index=False)

df = pd.read_csv('/content/czech_data_2005_2023.csv')
df['text_full_punctuation'] = df['text'].apply(model.restore_punctuation)
df.to_csv('/content/wto_kwic.csv', index=False)

import pandas as pd
from deepmultilingualpunctuation import PunctuationModel
from tqdm.auto import tqdm

model = PunctuationModel(model="kredor/punctuate-all")

def restore_punctuation_in_chunks(text, chunk_size=500):
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text)
    if len(text) <= chunk_size:
        return model.restore_punctuation(text)
    else:
        # Split into chunks, ensuring no empty chunks
        chunks = []
        for i in range(0, len(text), chunk_size):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk)
        if not chunks:
            return text
        punctuated_chunks = []
        for chunk in chunks:
            try:
                punctuated_chunks.append(model.restore_punctuation(chunk))
            except Exception as e:
                print(f"Error processing chunk: {e}. Skipping chunk: {chunk[:50]}...")
                punctuated_chunks.append(chunk)
        return " ".join(punctuated_chunks)

# Load data
df = pd.read_csv('/content/czech_data_2005_2023.csv')

# Process with progress bar
tqdm.pandas()
df['text_full_punctuation'] = df['text'].progress_apply(
    lambda x: restore_punctuation_in_chunks(x, chunk_size=500)
)

# Save results
df.to_csv('/content/wto_kwic.csv', index=False)

df = pd.read_csv('/content/left.csv')
df['context_full_punctuation'] = df['context_full'].apply(model.restore_punctuation)
df.to_csv('/content/left.csv', index=False)

df = pd.read_csv('/content/right.csv')
df['context_full_punctuation'] = df['context_full'].apply(model.restore_punctuation)
df.to_csv('/content/right.csv', index=False)

"""# Plenary Speech Translation

"""

model = EasyNMT('opus-mt')
#model = EasyNMT('m2m_100_1.2B')

nltk.download('punkt_tab')

texts_to_translate = df['text'].fillna('').tolist()
#texts_to_translate = df['context_full'].fillna('').tolist()

# batch size
batch_size = 32
translated_texts = []

# Wrap your loop with tqdm to display a progress bar.
# The 'total' argument sets the total number of iterations, which is the number of batches.
num_batches = (len(texts_to_translate) + batch_size - 1) // batch_size
for i in tqdm(range(0, len(texts_to_translate), batch_size), total=num_batches, desc="Translating batches"):
    batch = texts_to_translate[i:i + batch_size]
    batch_translations = model.translate(batch, source_lang='cs', target_lang='en')
    translated_texts.extend(batch_translations)

# add translated column
#df['translated_context_full_m2m'] = translated_texts
df['translated_context_full_opus'] = translated_texts

#df.to_csv('/content/left_translated_m2m.csv', index=False)
df.to_csv('/content/left_translated_opus.csv', index=False)

texts_to_translate = df['context_full_punctuation'].fillna('').tolist()
#texts_to_translate = df['context_full'].fillna('').tolist()

# batch size
batch_size = 10
translated_texts = []

# Wrap your loop with tqdm to display a progress bar.
# The 'total' argument sets the total number of iterations, which is the number of batches.
num_batches = (len(texts_to_translate) + batch_size - 1) // batch_size
for i in tqdm(range(0, len(texts_to_translate), batch_size), total=num_batches, desc="Translating batches"):
    batch = texts_to_translate[i:i + batch_size]
    batch_translations = model.translate(batch, source_lang='cs', target_lang='en')
    translated_texts.extend(batch_translations)

# add translated column
#df['translated_context_full_m2m'] = translated_texts
df['translated_context_full_opus'] = translated_texts

#df.to_csv('/content/left_translated_m2m.csv', index=False)
df.to_csv('/content/right_translated_opus.csv', index=False)