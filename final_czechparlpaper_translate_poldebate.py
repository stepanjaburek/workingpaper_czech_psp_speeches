# -*- coding: utf-8 -*-
"""Final_CzechParlPaper_Translate_PolDEBATE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fv-RcIbXpHo3o_LMVZ_JvmiyM9HYdx42

<a href="https://colab.research.google.com/github/stepanjaburek/workingpaper_czech_psp_speeches/blob/main/streamline_translation_sentiment.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# **Machine translation using the Opus-MT model from Uni Helsinky**

# Setup
"""

!pip install transformers sentencepiece sacremoses torch tqdm

import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
from tqdm.notebook import tqdm
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

def translate_csv(file_path, source_lang='cs', target_lang='en', batch_size=8):
    df=pd.read_csv(file_path)
    model_name = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name).to('cuda' if torch.cuda.is_available() else 'cpu')

    def translate_batch(texts):
        inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=512)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        with torch.no_grad():
            return tokenizer.batch_decode(model.generate(**inputs), skip_special_tokens=True)

    translations = []
    for i in tqdm(range(0, len(df), batch_size)):
        translations.extend(translate_batch(df['context_full'][i:i + batch_size].tolist()))

    df['translated_context_full'] = translations
    return df

"""# Translation left

"""

translated_df = translate_csv('/content/left.csv')
translated_df.to_csv('left_translated.csv', index=False)

"""# Translation right"""

translated_df = translate_csv('/content/right.csv')
translated_df.to_csv('right_translated.csv', index=False)

"""# **Machine translation using the NLLB-200 model from Meta**"""

def translate_csv_nllb(file_path, source_lang='ces_Latn', target_lang='eng_Latn', batch_size=4, max_length=256):

    df = pd.read_csv(file_path)
    model_name = 'facebook/nllb-200-distilled-1.3B'
    tokenizer = AutoTokenizer.from_pretrained(model_name, src_lang=source_lang)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda' if torch.cuda.is_available() else 'cpu')
    target_token_id = tokenizer.convert_tokens_to_ids(target_lang)

    def translate_batch(texts):
        inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=max_length).to(model.device)
        outputs = model.generate(**inputs, forced_bos_token_id=target_token_id, max_length=max_length)
        return tokenizer.batch_decode(outputs, skip_special_tokens=True)

    df['translated_context_full'] = [
        translation for i in tqdm(range(0, len(df), batch_size))
        for translation in translate_batch(df['context_full'][i:i + batch_size].tolist())
    ]
    return df

translated_df = translate_csv_nllb('/content/left.csv')
translated_df.to_csv('left_translated.csv', index=False)

translated_df = translate_csv_nllb('/content/right.csv')
translated_df.to_csv('right_translated.csv', index=False)

"""# **Sentiment classification using the Political DEBATE model by Burnham et al. (2024)**

# Setup
"""

def analyze_sentiments(df, classifier, classes, hypothesis, batch_size=16):
    results = []
    for i in tqdm(range(0, len(df), batch_size)):
        batch_output = classifier(
            df['translated_context_full'][i:i + batch_size].tolist(),
            classes,
            hypothesis_template=hypothesis,
            multi_label=False,
            batch_size=batch_size
        )

        for item in batch_output:
            results.append({
                'label': item['labels'][0],
                'score': item['scores'][0],
                **{f'{label}_score': score for label, score in zip(item['labels'], item['scores'])}
            })

    return pd.DataFrame(results)

"""# Model specification and labeling - Left"""

model_name = "mlburnham/Political_DEBATE_large_v1.0"
hypothesis_template =  "The emotional valence of this text towards the political left is {}"
classes = [ "negative", "neutral", "positive"]

device = 0 if torch.cuda.is_available() else -1
classifier = pipeline("zero-shot-classification",
                     model=model_name,
                     device=device)

df = pd.read_csv("/content/left_translated.csv")
results = analyze_sentiments(df, classifier, classes, hypothesis_template)

pd.concat([df, results], axis=1).to_csv('debate_sentiment_left.csv', index=False)


print("\nSentiment Distribution:")
print(results['label'].value_counts())

"""# Model specification and labeling - Right"""

model_name = "mlburnham/Political_DEBATE_large_v1.0"
hypothesis_template =  "The emotional valence of this text towards the political right is {}"
classes = [ "negative", "neutral", "positive"]

device = 0 if torch.cuda.is_available() else -1
classifier = pipeline("zero-shot-classification",
                     model=model_name,
                     device=device)

df = pd.read_csv("/content/right_translated.csv")
results = analyze_sentiments(df, classifier, classes, hypothesis_template)


pd.concat([df, results], axis=1).to_csv('debate_sentiment_right.csv', index=False)


print("\nSentiment Distribution:")
print(results['label'].value_counts())

"""# Model specification and labeling - Topic Modeling Left"""

!pip install gensim==4.3.3 --quiet

import os
os.kill(os.getpid(), 9)

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
import matplotlib.pyplot as plt
import seaborn as sns
from gensim.utils import simple_preprocess
from gensim.models import KeyedVectors

#df = pd.read_csv("/content/debate_topic_left_meta.csv")
#df = pd.read_csv("/content/debate_topic_right_meta.csv")

df = pd.read_csv("/content/sample_data/parlstories.csv")

combined_df = pd.concat([df, de], axis=0)

# Display the result
combined_df
df = combined_df

df

# Ensure all values are string and fill NaNs
df['text'] = df['text'].fillna('').astype(str)
texts = df['text']
corpus = texts.progress_apply(lambda x: simple_preprocess(x, deacc=False)) # finalize using gensim's simple_preprocess
print(corpus.head())

    # Create a document-term matrix
count_vectorizer = CountVectorizer(
        stop_words='english',  # Remove English stop words
        max_df=0.9,           # Ignore terms that appear in >95% of documents
        min_df=5,              # Ignore terms that appear in <2 documents
        max_features=2000      # Limit vocabulary size
    )

doc_term_matrix = count_vectorizer.fit_transform(texts)
feature_names = count_vectorizer.get_feature_names_out()

# For 4500 short texts, you might want to try a smaller number of topics
lda_model = LatentDirichletAllocation(
    n_components=8,         # Reduced from 10 to 8 (adjust based on your domain knowledge)
    random_state=42,        # For reproducibility
    learning_method='online',
    max_iter=25,
    n_jobs=-1              # Use all available cores for faster processing
)

lda_output = lda_model.fit_transform(doc_term_matrix)

# Function to display the top terms in each topic
def display_topics(model, feature_names, no_top_words):
    topic_dict = {}
    for topic_idx, topic in enumerate(model.components_):
        topic_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]
        topic_dict[topic_idx] = topic_words
        print(f"Topic {topic_idx}: {' '.join(topic_words)}")
    return topic_dict

# Display top 15 words in each topic (increased from 10)
topic_dict = display_topics(lda_model, feature_names, 15)

# Calculate and print perplexity score (lower is better)
perplexity = lda_model.perplexity(doc_term_matrix)
print(f"Perplexity: {perplexity}")

# Assign dominant topic to each document
topic_names = [f"Topic {i}" for i in range(lda_model.n_components)]
doc_topic_df = pd.DataFrame(lda_output, columns=topic_names)

# Get dominant topic for each document
dominant_topic = np.argmax(lda_output, axis=1)
df['dominant_topic'] = dominant_topic

# Visualization - plot the distribution of topics
plt.figure(figsize=(12, 6))
sns.countplot(x='dominant_topic', data=df)
plt.title('Distribution of Dominant Topics')
plt.xlabel('Topic Number')
plt.ylabel('Number of Documents')
plt.xticks(range(lda_model.n_components))
plt.show()

doc_topic_dist

model_name = "mlburnham/Political_DEBATE_large_v1.0"
hypothesis_template = "This text discusses the political left in terms of {}"
classes = ["economic issues",
    "social/cultural issues",
    "institutional issues",
    "historical issues",
    "foreign policy issues"]

device = 0 if torch.cuda.is_available() else -1
classifier = pipeline("zero-shot-classification",
                     model=model_name,
                     device=device)

df = pd.read_csv("/content/left_translated.csv")
results = analyze_sentiments(df, classifier, classes, hypothesis_template)


pd.concat([df, results], axis=1).to_csv('debate_topic_left.csv', index=False)


print("\nSentiment Distribution:")
print(results['label'].value_counts())